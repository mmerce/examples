;; Extracts the list of optimls and test dataset from the outputs of
;; a bal-optiml-script execution

(define execution-info (fetch (wait bal-optiml-exec)))

;; Obtain output item from an execution by its name
(define (inout-from-exec exec inout-name type)
  (let (inputs (get execution-info "inputs" [])
        outputs (get (get execution-info "execution" {}) "outputs" [])
        inouts (if (= "outputs" type)
                   outputs
                   inputs)
        options (when (not (empty? inouts))
                  (filter (lambda (o) (= (head o) inout-name)) inouts)))
    (when (not (empty? options))
      ((head options) 1))))

(define (output-from-exec exec output-name)
  (inout-from-exec exec output-name "outputs"))


(define (input-from-exec exec input-name)
  (inout-from-exec exec input-name "inputs"))

(define undersampled-optimls (output-from-exec bal-optiml-exec
                                               "undersampled-optimls"))
(define test-dataset (output-from-exec bal-optiml-exec "unbalanced-test-ds"))
(define project-id ((fetch (wait test-dataset)) "project"))
(define unbalanced-optiml (output-from-exec bal-optiml-exec "unbalanced-optiml"))
(define metric (input-from-exec bal-optiml-exec "metric"))
(define class (input-from-exec bal-optiml-exec "positive-class"))

(define (get-models optiml-id)
  (let (optiml (fetch (wait optiml-id))
        model-evals (optiml ["optiml" "models"])
        models (for (model model-evals)
                 (model "id"))
        evaluations (for (model model-evals)
                      (model ["evaluation" "id"]))
        class-filter-fn (lambda (ev) (= (ev "class_name") class))
        per-class-stats (for (info model-evals)
                          ((filter class-filter-fn
                                   (info ["evaluation"
                                          "info"
                                          "per_class_statistics"])) 0))
        models-info (iterate (acc []
                              model models
                              eval evaluations
                              stat per-class-stats)
                      (append acc
                              {"id" model
                               "eval_type" "validation"
                               "evaluation" eval
                               "metric_name" metric
                               "metric" (stat metric)
                               "max_phi" ((stat "max_phi") 0)
                               "probability_threshold" ((stat "max_phi") 1)})))
    (reverse (sort-by-key "metric" models-info))))

(define best-unbalanced-model (try
                                (head (get-models unbalanced-optiml))
                                (catch e (log-info "The unbalanced optiml was not built"
                                                   e))))

(define (get-best-models undersampled-optimls)
  ;; getting best models
  (iterate (acc [] optiml-id undersampled-optimls)
    (try
      (append acc (head (get-models optiml-id)))
      (catch e acc))))

(define undersampled-best-models (reverse (sort-by-key "metric"
                                   (get-best-models undersampled-optimls))))

(define (create-test-evals models)
  (let (model-ids (map (lambda (m) (m "id")) models)
        evals (for (model-id model-ids)
                (create-evaluation {"model" model-id
                                    "dataset" test-dataset
                                    "project" project-id})))
    (map extract-eval-info evals model-ids)))

(define (extract-eval-info eval-id model-id)
  (let (evaluation (fetch (wait eval-id))
        evals (evaluation ["result" "model" "per_class_statistics"])
        class-filter-fn (lambda (ev) (= (ev "class_name") class))
        model-id model-id
        stat ((filter class-filter-fn evals) 0))
    {"metric_name" metric
     "eval_type" "test"
     "evaluation" (evaluation "resource")
     "model" model-id
     "metric" (stat metric)
     "max_phi" ((stat "max_phi") 0)
     "probability_threshold" ((stat "max_phi") 1)}))

(define best-unbalanced-test (head (create-test-evals
                                     [best-unbalanced-model])))

(define better-models
  (let (ref-metric (best-unbalanced-model "metric")
        ref-max-phi (best-unbalanced-model "max_phi"))
    (reverse (sort-by-key "metric"
      (filter (lambda (m) (and (> (m "metric") ref-metric)
                               (> (m "max_phi") ref-max-phi)))
              undersampled-best-models)))))

(define better-models-tests (reverse (sort-by-key "metric"
                              (create-test-evals better-models))))
